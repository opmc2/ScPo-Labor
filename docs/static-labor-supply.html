<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Static Labor Supply</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.0/gh-fork-ribbon.min.css" />
<!--[if lt IE 9]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.0/gh-fork-ribbon.ie.min.css" />
<![endif]-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ScPo-GradLabour</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-pencil"></span>
     
    Homeworks
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="static-labor-supply.html">Static LS</a>
    </li>
    <li>
      <a href="hw-lifecycle-solutions.html">Lifecycle Model</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/floswald/ScPo-Labor">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/floswald/ScPo-Labor/issues">
    <span class="fa fa-bug"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Static Labor Supply</h1>

</div>


<p>You can find the source code for this file in the class repository. The direct link is <a href="https://raw.githubusercontent.com/tlamadon/econ-34430/master/src/static-labor-supply.Rmd">here</a></p>
<p>Let’s start with studying static labor supply. We will consider the decision of the agent under the following rule:</p>
<p><span class="math display">\[
\max_{c,h} \frac{c^{1+\eta}}{1+\eta} - \beta \frac{h^{1+\gamma}}{1+\gamma}\\
\text{s.t. } c = \rho \cdot w\cdot h -r + \mu - \beta_0 \cdot 1[h&gt;0] \\ 
\]</span> The individual takes his wage <span class="math inline">\(w\)</span> as given, he chooses hours of work <span class="math inline">\(h\)</span> and consumption <span class="math inline">\(c\)</span> subject to a given non labor income <span class="math inline">\(\mu\)</span> as well as a tax regime defined by <span class="math inline">\(\rho,r\)</span>. <span class="math inline">\(\beta_0\)</span> is a fixed cost associated with working.</p>
<p>We note already that the non-labor income can control for dynamic labor supply since we can have <span class="math inline">\(\mu= b_t - (1+r)b_{t+1}\)</span>. This is part of a larger maximization problem where the agents choose optimaly <span class="math inline">\(b_t\)</span> over time. We will get there next time.</p>
<div id="interior-solution" class="section level3">
<h3>Interior solution</h3>
<p>The first order conditions give us <span class="math inline">\(w(wh +r - \mu)^\eta = \beta h^\gamma\)</span>. There is no closed-form but we can very quickly find an interior solution by using Newton maximization on the function <span class="math inline">\(f(x) = w(wh +r - \mu)^\eta - \beta h^\gamma\)</span>. We iterate on</p>
<p><span class="math display">\[
x \leftarrow x - f(x)/f&#39;x)
\]</span>.</p>
<pre class="r"><code># function which updates choice of hours using Newton step
# R here is total unearned income (including taxes when not working and all)
ff.newt &lt;- function(x,w,R,eta,gamma,beta) {
  f0 = w*(w*x + R)^eta - beta*x^gamma
  f1 =  eta*w^2 * (w*x + R)^(eta-1) - gamma * beta *x^(gamma-1)
  x  = x - f0/f1 
  x  = ifelse(w*x + R&lt;=0, -R/w + 0.0001,x) # make sure we do not step out of bounds for next iteration
  x  = ifelse(x&lt;0, 0.0001,x)
  x
}</code></pre>
</div>
<div id="simulating-data" class="section level3">
<h3>Simulating data</h3>
<p>We are going to simulate a data set where agents will choose participation as well as the number of hours if they decide to work. To do that we will solve for the interior solution under a given tax rate and compare this to the option of no-work.</p>
<pre class="r"><code>p  = list(eta=-1.5,gamma = 0.8,beta=1,beta0=0.1) # define preferences
tx = list(rho=1,r=0) # define a simple tax
N=1000
simdata = data.table(i=1:N,X=rnorm(N))
simdata[,lw := X     + rnorm(N)*0.2];      # add a wage which depends on X
simdata[,mu := exp(0.3*X + rnorm(N)*0.2)]; # add non-labor income that also depends on X

# we then solve for the choice of hours and consumption
simdata[, h := pmax(-mu+tx$r + p$beta0 ,0)/exp(lw)+1] # starting value
# for loop for newton method (30 should be enough, it is fast)
for (i in 1:30) {
  simdata[, h := ff.newt(h,tx$rho*exp(lw),mu-tx$r-p$beta0,p$eta,p$gamma,p$beta) ]
}

# attach consumption, value of working
simdata[, c  := exp(lw)*h + mu - p$beta0];
simdata[, u1 := c^(1+p$eta)/(1+p$eta) - p$beta * h^(1+p$gamma)/(1+p$gamma) ];</code></pre>
<p>At this point we can regress <span class="math inline">\(\log(w)\)</span> on <span class="math inline">\(\log(c)\)</span> and <span class="math inline">\(\log(h)\)</span> and find precisely the parameters of labor supply:</p>
<pre class="r"><code>pander(summary(simdata[,lm(lw ~ log(c) + log(h))]))</code></pre>
<pre><code>## Warning in summary.lm(simdata[, lm(lw ~ log(c) + log(h))]): essentially
## perfect fit: summary may be unreliable</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">1.5</td>
<td align="center">1.458e-17</td>
<td align="center">1.029e+17</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.8</td>
<td align="center">3.726e-17</td>
<td align="center">2.147e+16</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">1.123e-16</td>
<td align="center">3.196e-17</td>
<td align="center">3.515</td>
<td align="center">0.0004595</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1000</td>
<td align="center">2.708e-16</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#pander(summary(simdata[,lm(log(h) ~ log(c) + log(c - h*exp(lw)))]))</code></pre>
</div>
<div id="adding-participation" class="section level2">
<h2>Adding participation</h2>
<p>We simply compute the value of choosing <span class="math inline">\(h=0\)</span>, then take the highest of working and not working.</p>
<pre class="r"><code>simdata[,u0:=  mu^(1+p$eta)/(1+p$eta)];
simdata[,p1:=u1&gt;u0]
ggplot(simdata,aes(x=u0,y=u1)) + geom_point() + geom_abline(linetype=2)</code></pre>
<p><img src="static-labor-supply_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The regression still works, among each individual who chooses to work, the FOC is still satisfied.</p>
<pre class="r"><code>pander(summary(simdata[p1==TRUE,lm(lw ~ log(c) + log(h))]))</code></pre>
<pre><code>## Warning in summary.lm(simdata[p1 == TRUE, lm(lw ~ log(c) + log(h))]):
## essentially perfect fit: summary may be unreliable</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">1.5</td>
<td align="center">1.969e-17</td>
<td align="center">7.619e+16</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.8</td>
<td align="center">7.128e-17</td>
<td align="center">1.122e+16</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">3.833e-16</td>
<td align="center">4.904e-17</td>
<td align="center">7.817</td>
<td align="center">1.784e-14</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">773</td>
<td align="center">2.826e-16</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
</div>
<div id="heterogeneity-in-beta" class="section level2">
<h2>Heterogeneity in <span class="math inline">\(\beta\)</span></h2>
<p>Finally we want to add heterogeneity in the <span class="math inline">\(\beta\)</span> parameter.</p>
<pre class="r"><code>simdata[,betai := exp(0.5*X+rnorm(N)*0.1)]
simdata[, h := pmax(-mu+tx$r + p$beta0 ,0)/exp(lw)+1]
for (i in 1:30) {
  simdata[, h := ff.newt(h,tx$rho*exp(lw),mu-tx$r-p$beta0,p$eta,p$gamma,betai) ]
}

# attach consumption
simdata[, c  := exp(lw)*h + mu - p$beta0];
simdata[, u1 := c^(1+p$eta)/(1+p$eta) - betai * h^(1+p$gamma)/(1+p$gamma) ];
simdata[, u0:=  mu^(1+p$eta)/(1+p$eta)];
simdata[,p1:=u1&gt;u0]

# let&#39;s check that the FOC holds
sfit = summary(simdata[,lm(lw ~ log(c) + log(h) + log(betai))])</code></pre>
<pre><code>## Warning in summary.lm(simdata[, lm(lw ~ log(c) + log(h) + log(betai))]):
## essentially perfect fit: summary may be unreliable</code></pre>
<pre class="r"><code>expect_equivalent(sfit$r.squared,1)
expect_equivalent(coef(sfit)[&quot;log(c)&quot;,1],-p$eta)
expect_equivalent(coef(sfit)[&quot;log(h)&quot;,1],p$gamma)

sfit = summary(simdata[p1==TRUE,lm(lw ~ log(c) + log(h))])
expect_false(coef(sfit)[&quot;log(c)&quot;,1]==-p$eta)</code></pre>
<pre class="r"><code>pander(sfit)</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">2.123</td>
<td align="center">0.02263</td>
<td align="center">93.84</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.2957</td>
<td align="center">0.0302</td>
<td align="center">9.792</td>
<td align="center">1.58e-21</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.5621</td>
<td align="center">0.01556</td>
<td align="center">-36.12</td>
<td align="center">3.741e-174</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">857</td>
<td align="center">0.1564</td>
<td align="center">0.966</td>
<td align="center">0.9659</td>
</tr>
</tbody>
</table>
</div>
<div id="short-panel-version" class="section level1">
<h1>Short Panel version</h1>
<p># Short Panel version</p>
<p><strong>Q1:</strong> Take the simulated data from the model with heterogenous <span class="math inline">\(\beta_i\)</span>. First explain why regressing <span class="math inline">\(\log(w)\)</span> on <span class="math inline">\(\log(c)\)</span>, <span class="math inline">\(\log(h)\)</span>, and <span class="math inline">\(X\)</span> does not deliver correct estimates.</p>
<p><strong>Answer:</strong></p>
<p>By introducing heterogeneity in <span class="math inline">\(\beta_i\)</span>, we create a variation in <span class="math inline">\(h\)</span> that depends on the individual. Without stripping <span class="math inline">\(h\)</span> of the effect of <span class="math inline">\(\beta_i\)</span>, we effectively run a pooled OLS regression. We can see the effect of the heterogeneity on in the following plot. (<span class="math inline">\(f0/f1\)</span> increases in <span class="math inline">\(\beta_i\)</span>, leading to a downward effect on <span class="math inline">\(h^*\)</span>):</p>
<pre class="r"><code>plot(simdata$betai ,simdata$h)</code></pre>
<p><img src="static-labor-supply_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The pooled OLS returns a biased estimate. The bias should be smaller within restricted ranges, or clusters, of <span class="math inline">\(\beta_i\)</span>:</p>
<pre class="r"><code>lbeta=summary(simdata[(p1==TRUE) &amp; (betai&lt;quantile(betai , 0.25 )),lm(lw ~ log(c) + log(h))])
mbeta=summary(simdata[(p1==TRUE) &amp; (betai&gt;quantile(betai , 0.25 )) &amp; (betai&lt;quantile(betai , 0.75 )),lm(lw ~ log(c) + log(h))])
hbeta=summary(simdata[(p1==TRUE) &amp; (betai&gt;quantile(betai, .75)),lm(lw ~ log(c) + log(h))])</code></pre>
<pre class="r"><code>#for example:
pander(lbeta)</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">1.65</td>
<td align="center">0.06835</td>
<td align="center">24.14</td>
<td align="center">7.236e-50</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.4149</td>
<td align="center">0.06093</td>
<td align="center">6.81</td>
<td align="center">3.259e-10</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.6396</td>
<td align="center">0.02385</td>
<td align="center">-26.82</td>
<td align="center">7.948e-55</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">133</td>
<td align="center">0.1066</td>
<td align="center">0.8485</td>
<td align="center">0.8462</td>
</tr>
</tbody>
</table>
<pre class="r"><code>pander(hbeta)</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">2.019</td>
<td align="center">0.03232</td>
<td align="center">62.46</td>
<td align="center">2.604e-153</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.4239</td>
<td align="center">0.046</td>
<td align="center">9.216</td>
<td align="center">1.399e-17</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.2556</td>
<td align="center">0.04096</td>
<td align="center">-6.239</td>
<td align="center">1.899e-09</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">250</td>
<td align="center">0.1279</td>
<td align="center">0.9537</td>
<td align="center">0.9534</td>
</tr>
</tbody>
</table>
<p>Indeed, the bias decreases in this clustered regression. Furthermore, the bias is lowest for the smallest values of <span class="math inline">\(\beta_i\)</span>. In effect, by not controlling for <span class="math inline">\(\beta_i\)</span>, we get the effect on the average <span class="math inline">\(\beta_i\)</span>. To see this:</p>
<pre class="r"><code># compare with pander(sfit) above
pander(summary(simdata[(p1==TRUE) &amp; (betai=mean(betai)),lm(lw ~ log(c) + log(h))]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">2.123</td>
<td align="center">0.02263</td>
<td align="center">93.84</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.2957</td>
<td align="center">0.0302</td>
<td align="center">9.792</td>
<td align="center">1.58e-21</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.5621</td>
<td align="center">0.01556</td>
<td align="center">-36.12</td>
<td align="center">3.741e-174</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h)</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">857</td>
<td align="center">0.1564</td>
<td align="center">0.966</td>
<td align="center">0.9659</td>
</tr>
</tbody>
</table>
<p><strong>Q2:</strong> Simulate 2 periods of the model (a short panel), keep everything fixed over the 2 periods, but redraw the wage. Estimate the model in differences and recover the parameters using <span class="math inline">\(\log(w)\)</span> on <span class="math inline">\(\log(c)\)</span>, <span class="math inline">\(\log(h)\)</span>. How does including or not including participation decision affect the results? Explain.</p>
<p><strong>Answer</strong></p>
<pre class="r"><code>#re-do simulation with second period
N= 1000
T=2
simdata= data.table(i=rep((1:N),T), X = rnorm(N))
simdata[, t   := kronecker(c(1:T), rep(1,N))];
simdata[,lw   := X          + rnorm(2*N)*0.2]; #2*N So each period gets its own
simdata[,mu   :=   exp(0.3*X + rnorm(N)*0.2)];
simdata[, h   := pmax(-mu+tx$r + p$beta0 ,0)/exp(lw)+1]
simdata[,betai:=     exp(0.5*X+rnorm(N)*0.1)]

#maximization
for (i in 1:30) {
  simdata[, h := ff.newt(h,tx$rho*exp(lw),mu-tx$r-p$beta0,p$eta,p$gamma,betai) ]
}

#backing out consumption, utilities, participation decision
simdata[, c  := exp(lw)*h + mu - p$beta0];
simdata[, u1 := c^(1+p$eta)/(1+p$eta) - betai * h^(1+p$gamma)/(1+p$gamma) ];
simdata[, u0 :=  mu^(1+p$eta)/(1+p$eta)];
simdata[,p1  :=u1&gt;u0]

#differences 
#new data table as each individual has only one entry (difference so no periods)
diffs= data.table(i=1:N)
for (j in 1:N) {
diffs$dlc[j]= simdata[(t==2) &amp; (i==j), log(c)]-simdata[(t==1) &amp; (i==j),log(c)]
diffs$dlh[j]= simdata[(t==2) &amp; (i==j), log(h)]-simdata[(t==1) &amp; (i==j),log(h)]
diffs$dlw[j]= simdata[(t==2) &amp; (i==j), lw]-simdata[(t==1) &amp; (i==j),lw]
}</code></pre>
<pre class="r"><code># Regressions
pander(summary(diffs[,lm(dlw ~ dlc + dlh)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>dlc</strong></td>
<td align="center">1.5</td>
<td align="center">9.516e-17</td>
<td align="center">1.576e+16</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>dlh</strong></td>
<td align="center">0.8</td>
<td align="center">1.13e-16</td>
<td align="center">7.082e+15</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-1.712e-17</td>
<td align="center">8.931e-18</td>
<td align="center">-1.916</td>
<td align="center">0.0556</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: dlw ~ dlc + dlh</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1000</td>
<td align="center">2.819e-16</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#pander(summary(diffs[p1==TRUE ,lm(dlw ~ dlc + dlh)]))
#pander(summary(diffs[p1==FALSE,lm(dlw ~ dlc + dlh)]))</code></pre>
<p>Unlike the previous results, these regressions are correct. By taking the difference, we cancel out any time-invariant effects, including that from <span class="math inline">\(\beta_i\)</span>.</p>
<p>Now, we assume that workers who never work are non-participants.</p>
<pre class="r"><code>invisible(simdata[,worker:=1])

#marking non-participants
for (k in 1:N) {
  simdata[t==1 &amp; i==k, q:=p1]
  simdata[t==2 &amp; i==k, r:=p1]
}
invisible(simdata[q==FALSE &amp; r==FALSE,worker:=0])

diffs=cbind(diffs, simdata$worker[1:N])
pander(summary(diffs[V2==1,lm(dlw ~ dlc + dlh)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>dlc</strong></td>
<td align="center">1.5</td>
<td align="center">9.516e-17</td>
<td align="center">1.576e+16</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>dlh</strong></td>
<td align="center">0.8</td>
<td align="center">1.13e-16</td>
<td align="center">7.082e+15</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-1.712e-17</td>
<td align="center">8.931e-18</td>
<td align="center">-1.916</td>
<td align="center">0.0556</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: dlw ~ dlc + dlh</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1000</td>
<td align="center">2.819e-16</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>If we run the regression, we drop 84 observations and the results are unchanged. We now verify that this holds if we drop more observations. We now consider workers only those who work in <strong>both</strong> periods.</p>
<pre class="r"><code>diffs= diffs[,-5]
for (k in 1:N) {
  q = simdata[t==1 &amp; i==k, p1]
  r = simdata[t==2 &amp; i==k, p1]
  ifelse((q==FALSE | r==FALSE), simdata[k,12]&lt;-0, simdata[k,12]&lt;-1)
  ifelse((q==FALSE | r==FALSE), simdata[k+N,12]&lt;-0, simdata[k+N,12]&lt;-1)
}
diffs=cbind(diffs, simdata$worker[1:N])
pander(summary(diffs[V2==1,lm(dlw ~ dlc + dlh)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>dlc</strong></td>
<td align="center">1.5</td>
<td align="center">1.2e-16</td>
<td align="center">1.25e+16</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>dlh</strong></td>
<td align="center">0.8</td>
<td align="center">1.95e-16</td>
<td align="center">4.103e+15</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-1.231e-17</td>
<td align="center">9.888e-18</td>
<td align="center">-1.245</td>
<td align="center">0.2137</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: dlw ~ dlc + dlh</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">827</td>
<td align="center">2.836e-16</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>With a broader notion of participation, we drop 168 observations and the regression is still nearly identical. When we take the differences, we remove the effect of any time-invariant factors. As such, as long as we do not interfere with this process, (by somehow adding high X or high <span class="math inline">\(\beta\)</span> agents to one of the periods) there will be no bias in the regression. Indeed, when we remove non-participants, we remove the same agent from both periods and introduce no bias to the regression.</p>
</div>
<div id="repeated-cross-section-version" class="section level1">
<h1>Repeated cross-section version</h1>
<p>In this section we want to get closer to the Blundell, Duncan and Meghir (1998) exercise. We first modify the cost to allow for an increased return to X, and for the presence of a change in the tax rate. Simulate wages according to:</p>
<pre><code>  simdata[,lw := lb*X + rnorm(N)*0.2];      # add a wage which depends on X</code></pre>
<p>Write a function that can simulate a full cross section and that takes <code>lb</code> as an input as well as marginal tax rate <span class="math inline">\(\rho\)</span>. It should apply the same function as before to solve for the interior solution, but use the after-tax wage everywhere.</p>
<pre class="r"><code>full_cross_section2 &lt;- function(lb, N, rho, X){ #function to keep track of individuals - same X
  #parameters
  p  = list(eta=-1.5,gamma = 0.8,beta=1,beta0=0.1) # define preferences
  
  #simulating data
  simdata = data.table(i=1:N,X)
  simdata[,lw := lb*X + rnorm(N)*0.2];      # add a wage which depends on X and lb
  simdata[,mu := exp(0.3*X + rnorm(N)*0.2)]; # add non-labor income that also depends on X
  simdata[,betai := exp(0.5*X+rnorm(N)*0.1)]
  
  #hours first guess
  simdata[, h := pmax(-mu + p$beta0 ,0)/exp(lw)+1]
  
  #solve for choice of hours and consumption
  for (i in 1:30) {
    simdata[, h := ff.newt(h,rho*exp(lw),mu-tx$r-p$beta0,p$eta,p$gamma,betai) ]
  }

  # attach consumption
  simdata[, c  := rho*exp(lw)*h + mu - p$beta0];
  simdata[, u1 := c^(1+p$eta)/(1+p$eta) - betai * h^(1+p$gamma)/(1+p$gamma) ];
  simdata[, u0:=  mu^(1+p$eta)/(1+p$eta)];
  simdata[,p1:=u1&gt;u0]

}

full_cross_section &lt;- function(lb, N, rho, t){ # draws new X in period 2.
  #parameters
  p  = list(eta=-1.5,gamma = 0.8,beta=1,beta0=0.1) # define preferences
  
  #simulating data
  simdata = data.table(i=1:N,X=rnorm(N), t)
  simdata[,lw := lb*X + rnorm(N)*0.2];      # add a wage which depends on X and lb
  simdata[,mu := exp(0.3*X + rnorm(N)*0.2)]; # add non-labor income that also depends on X
  simdata[,betai := exp(0.5*X+rnorm(N)*0.1)]
  
  #hours first guess
  simdata[, h := pmax(-mu + p$beta0 ,0)/exp(lw)+1]
  
  #solve for choice of hours and consumption
  for (i in 1:30) {
    simdata[, h := ff.newt(h,rho*exp(lw),mu-p$beta0,p$eta,p$gamma,betai) ]
  }

  # attach consumption
  simdata[, c  := rho*exp(lw)*h + mu - p$beta0];
  simdata[, u1 := c^(1+p$eta)/(1+p$eta) - betai * h^(1+p$gamma)/(1+p$gamma) ];
  simdata[, u0:=  mu^(1+p$eta)/(1+p$eta)];
  simdata[,p1:=u1&gt;u0]
}</code></pre>
<p><strong>Q3:</strong> simulate two cross-sections with <span class="math inline">\((lb=1,\rho=1)\)</span> and <span class="math inline">\((lb=1.5,\rho=0.8)\)</span> and use 10k indivduals. Simulate data without the participation decision for now. Combine the data and show that previous regression provides biased estimates. Then slice X into K categories (for example using quantiles). Then compute <span class="math inline">\(\log(w)\)</span>, <span class="math inline">\(\log(c)\)</span> and <span class="math inline">\(\log(h)\)</span> within each group and time period. Run the regression in first differences and show that this recovers the structural parameters.</p>
<p>The combined data (from two cross-sections with different tax rates) produces biased estimates, <span class="math inline">\(\hat{\eta}\)</span> and <span class="math inline">\(\hat{\gamma}\)</span>. We have a similar problem to in Questions 1 and 2; we cannot separate out the individual effects of <span class="math inline">\(\beta_i\)</span> and the effects we want to identify i.e. <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\gamma\)</span>.</p>
<pre class="r"><code>simdata3 &lt;- rbind(full_cross_section(1,10000,1,0), full_cross_section(1.5,10000,.8,1))
#simdata2 &lt;- rbind(full_cross_section2(1,10000,1,rnorm(10000)), full_cross_section2(1.5,10000,.8,rnorm(10000)))
pander(summary(simdata3[,lm(lw ~ log(c) + log(h))]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">2.234</td>
<td align="center">0.002894</td>
<td align="center">772.2</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.6075</td>
<td align="center">0.00493</td>
<td align="center">123.2</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.3026</td>
<td align="center">0.004016</td>
<td align="center">-75.36</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h) We can follow the example in BDM (1998) and use group estimators to mimic panel data. Then we can take differences and control for (to some extent) the effects of <span class="math inline">\(\beta_i\)</span>.</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">20000</td>
<td align="center">0.2239</td>
<td align="center">0.9694</td>
<td align="center">0.9694</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#using the method suggested
quantX &lt;- quantile(simdata3$X, seq(0,1,.1))

invisible(simdata3[, q:= 0])
for (iter in 1:10){
  simdata3[X &gt; quantX[iter], q := iter]
}
w0 &lt;- simdata3[t==0,mean(lw),by=q]
w1 &lt;- simdata3[t==1,mean(lw),by=q]
c0 &lt;- simdata3[t==0,mean(log(c)),by=q]
c1 &lt;- simdata3[t==1,mean(log(c)),by=q]
h0 &lt;- simdata3[t==0,mean(log(h)),by=q]
h1 &lt;- simdata3[t==1,mean(log(h)),by=q]
D &lt;- data.table(q=1:min(length(w0[,q]),length(w1[,q])))
for (iter in 1:10){
  D[q==iter, lw := w1[q==iter,2] - w0[q==iter,2]]
  D[q==iter, lc := c1[q==iter,2] - c0[q==iter,2]]
  D[q==iter, lh := h1[q==iter,2] - h0[q==iter,2]]
}
pander(summary(D[,lm(lw ~ lc + lh)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>lc</strong></td>
<td align="center">1.491</td>
<td align="center">0.009171</td>
<td align="center">162.6</td>
<td align="center">8.79e-14</td>
</tr>
<tr class="even">
<td align="center"><strong>lh</strong></td>
<td align="center">0.7852</td>
<td align="center">0.00583</td>
<td align="center">134.7</td>
<td align="center">3.282e-13</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">0.2209</td>
<td align="center">0.001707</td>
<td align="center">129.4</td>
<td align="center">4.333e-13</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ lc + lh</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">10</td>
<td align="center">0.004329</td>
<td align="center">0.9999</td>
<td align="center">0.9999</td>
</tr>
</tbody>
</table>
<p><strong>Q4:</strong> Add the participation decision to the data generating process. Show that the results are now biased.</p>
<p>When we take participation into account and remove individuals from the data who do not participate, we see that the estimates are biased. The source of the bias is quite subtle. (assuming it is bias and not imprecision—we should really run the regression many times and check the different estimates to verify biasedness). The grouping relies on the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(\beta_i\)</span> being sufficient so that grouping and then taking within group differences <em>almost</em> eliminates the effects of <span class="math inline">\(\beta_i\)</span>. However, the participation decision breaks the equivalence of group mean <span class="math inline">\(\beta_i\)</span>’s across periods.</p>
<pre class="r"><code># using dummies
pander(summary(simdata3[p1==TRUE,lm(lw ~ log(c) + log(h) + t + q + t:q)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">1.684</td>
<td align="center">0.005157</td>
<td align="center">326.5</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.4374</td>
<td align="center">0.005794</td>
<td align="center">75.48</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>t</strong></td>
<td align="center">0.2449</td>
<td align="center">0.007337</td>
<td align="center">33.38</td>
<td align="center">7.414e-236</td>
</tr>
<tr class="even">
<td align="center"><strong>q</strong></td>
<td align="center">0.09517</td>
<td align="center">0.0008994</td>
<td align="center">105.8</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>t:q</strong></td>
<td align="center">-0.00539</td>
<td align="center">0.001042</td>
<td align="center">-5.171</td>
<td align="center">2.358e-07</td>
</tr>
<tr class="even">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-0.8194</td>
<td align="center">0.004142</td>
<td align="center">-197.8</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h) + t + q + t:q</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">15305</td>
<td align="center">0.1184</td>
<td align="center">0.9857</td>
<td align="center">0.9857</td>
</tr>
</tbody>
</table>
<pre class="r"><code># without dummies
pw0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(lw),by=q]
pw1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(lw),by=q]
pc0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(log(c)),by=q]
pc1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(log(c)),by=q]
ph0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(log(h)),by=q]
ph1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(log(h)),by=q]
pD &lt;- data.table(q=2:min(length(pw0[,q]),length(pw1 [,q])+1))
for (iter in 2:10){
  pD[q==iter, lw := pw1[q==iter,2] - pw0[q==iter,2]]
  pD[q==iter, lc := pc1[q==iter,2] - pc0[q==iter,2]]
  pD[q==iter, lh := ph1[q==iter,2] - ph0[q==iter,2]]
}
pander(summary(pD[,lm(lw ~ lc + lh)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>lc</strong></td>
<td align="center">1.49</td>
<td align="center">0.01085</td>
<td align="center">137.3</td>
<td align="center">1.005e-11</td>
</tr>
<tr class="even">
<td align="center"><strong>lh</strong></td>
<td align="center">0.7791</td>
<td align="center">0.05651</td>
<td align="center">13.79</td>
<td align="center">9.059e-06</td>
</tr>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">0.2209</td>
<td align="center">0.001934</td>
<td align="center">114.3</td>
<td align="center">3.03e-11</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ lc + lh</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">9</td>
<td align="center">0.00569</td>
<td align="center">0.9998</td>
<td align="center">0.9997</td>
</tr>
</tbody>
</table>
<p><strong>Q5:</strong> Extend the model to add an excluded variable that affects participation through <span class="math inline">\(\mu\)</span> but not the wage (keep X everywhere). Devise a way improve the estimates by controlling for participation.</p>
<pre class="r"><code>full_cross_section_IV &lt;- function(lb, N, rho,t){ # draws new X in period 2.
  #parameters
  p  = list(eta=-1.5,gamma = 0.8,beta=1,beta0=0.1) # define preferences
  
  #simulating data
  simdata = data.table(i=1:N,X=rnorm(N),Z=rnorm(N),t) # add variable Z drawn from rnorm
  simdata[,lw := lb*X + rnorm(N)*0.2];              # add a wage which depends on X and lb
  simdata[,mu := exp(0.3*X + .4*Z + rnorm(N)*0.2)]; # add non-labor income that also depends on X and now Z
  simdata[,betai := exp(0.5*X+rnorm(N)*0.1)]        # heterogenous betas
  
  #hours first guess
  simdata[, h := pmax(-mu + p$beta0 ,0)/exp(lw)+1]
  
  #solve for choice of hours and consumption
  for (i in 1:30) {
    simdata[, h := ff.newt(h,rho*exp(lw),mu-p$beta0,p$eta,p$gamma,betai) ]
  }

  # attach consumption
  simdata[, c  := rho*exp(lw)*h + mu - p$beta0];
  simdata[, u1 := c^(1+p$eta)/(1+p$eta) - betai * h^(1+p$gamma)/(1+p$gamma) ];
  simdata[, u0:=  mu^(1+p$eta)/(1+p$eta)];
  simdata[,p1:=u1&gt;u0]
}</code></pre>
<p>To control for participation we want to calculate the probability of working based on the observed variables, and then include this as a regressor in the wage equation. We use the excluded variable that affects wealth but not wages as an instrument—without <span class="math inline">\(Z\)</span> we would have nothing that shifts <span class="math inline">\(\mu\)</span> and hence the participation decision.</p>
<p>In the current setup, we want to find the inverse Mills ratio (iMr) to include as a control for selection. We follow very closely the steps in BDM(1998), where they highlight that a per group, per period iMr can be estimated as:</p>
<p><span class="math display">\[
  iMr = \frac{\phi(z)}{\Phi(z)}, \, \text{ where } z := \phi^{-1}(L_{gt})
\]</span> and <span class="math inline">\(L_{gt}\)</span> is the share of individuals in group <span class="math inline">\(g\)</span> who are working in period <span class="math inline">\(t\)</span>.</p>
<pre class="r"><code>#stage two with iMr 
stage2 = simdata3[, lm(lw~log(c)+log(h)+res+factor(q)*factor(t)+iMr)]
pander(summary(stage2))</code></pre>
<table>
<colgroup>
<col width="38%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>log(c)</strong></td>
<td align="center">1.315</td>
<td align="center">0.007413</td>
<td align="center">177.4</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>log(h)</strong></td>
<td align="center">0.6816</td>
<td align="center">0.003813</td>
<td align="center">178.8</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>res</strong></td>
<td align="center">0.2772</td>
<td align="center">0.005992</td>
<td align="center">46.27</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)2</strong></td>
<td align="center">0.2848</td>
<td align="center">0.00892</td>
<td align="center">31.93</td>
<td align="center">5.415e-218</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)3</strong></td>
<td align="center">0.4145</td>
<td align="center">0.01199</td>
<td align="center">34.58</td>
<td align="center">3.776e-254</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)4</strong></td>
<td align="center">0.5074</td>
<td align="center">0.01542</td>
<td align="center">32.91</td>
<td align="center">4.905e-231</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)5</strong></td>
<td align="center">0.6033</td>
<td align="center">0.01799</td>
<td align="center">33.53</td>
<td align="center">1.829e-239</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)6</strong></td>
<td align="center">0.681</td>
<td align="center">0.02077</td>
<td align="center">32.79</td>
<td align="center">1.871e-229</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)7</strong></td>
<td align="center">0.7625</td>
<td align="center">0.02406</td>
<td align="center">31.69</td>
<td align="center">7.023e-215</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)8</strong></td>
<td align="center">0.8326</td>
<td align="center">0.02894</td>
<td align="center">28.77</td>
<td align="center">2.954e-178</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)9</strong></td>
<td align="center">0.9641</td>
<td align="center">0.03412</td>
<td align="center">28.26</td>
<td align="center">3.827e-172</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)10</strong></td>
<td align="center">1.316</td>
<td align="center">0.03351</td>
<td align="center">39.27</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(t)1</strong></td>
<td align="center">0.1857</td>
<td align="center">0.004239</td>
<td align="center">43.8</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>iMr</strong></td>
<td align="center">0.2369</td>
<td align="center">0.01324</td>
<td align="center">17.89</td>
<td align="center">5.408e-71</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)2:factor(t)1</strong></td>
<td align="center">0.1278</td>
<td align="center">0.01114</td>
<td align="center">11.48</td>
<td align="center">2.179e-30</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)3:factor(t)1</strong></td>
<td align="center">0.1518</td>
<td align="center">0.01159</td>
<td align="center">13.09</td>
<td align="center">5.424e-39</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)4:factor(t)1</strong></td>
<td align="center">0.1575</td>
<td align="center">0.01132</td>
<td align="center">13.91</td>
<td align="center">8.52e-44</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)5:factor(t)1</strong></td>
<td align="center">0.1508</td>
<td align="center">0.01035</td>
<td align="center">14.58</td>
<td align="center">7.052e-48</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)6:factor(t)1</strong></td>
<td align="center">0.09737</td>
<td align="center">0.008095</td>
<td align="center">12.03</td>
<td align="center">3.351e-33</td>
</tr>
<tr class="even">
<td align="center"><strong>factor(q)7:factor(t)1</strong></td>
<td align="center">0.05357</td>
<td align="center">0.007101</td>
<td align="center">7.544</td>
<td align="center">4.763e-14</td>
</tr>
<tr class="odd">
<td align="center"><strong>factor(q)8:factor(t)1</strong></td>
<td align="center">0.0448</td>
<td align="center">0.007135</td>
<td align="center">6.279</td>
<td align="center">3.477e-10</td>
</tr>
<tr class="even">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">-1.113</td>
<td align="center">0.00947</td>
<td align="center">-117.5</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ log(c) + log(h) + res + factor(q) * factor(t) + iMr</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">19023</td>
<td align="center">0.1257</td>
<td align="center">0.9884</td>
<td align="center">0.9884</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#get .84 if I use z instead of m.
#could think harder about choosing the prper number of quantiles/groups.. it was much better with 4x4 instead of 10x 10</code></pre>
<pre class="r"><code>quantX &lt;- quantile(simdata3$X, seq(0,1,.1))
for (iter in 1:10){
  simdata3[X &gt;= quantX[iter], q := iter]
}

invisible(simdata3[, propw:= 0])
for (iter in 1:10){
  simdata3[q==iter &amp; t==0, propw := qnorm(mean(p1))]
  simdata3[q==iter &amp; t==1, propw := qnorm(mean(p1))]
}

#inverse mill ratio by group by time
invisible(simdata3[,iMr := dnorm(propw)/pnorm(propw)])

# without dummies
pw0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(lw),by=q]
pw1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(lw),by=q]
pc0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(log(c)),by=q]
pc1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(log(c)),by=q]
ph0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(log(h)),by=q]
ph1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(log(h)),by=q]
iMr0 &lt;- simdata3[p1==TRUE &amp; t==0,mean(iMr),by=q]
iMr1 &lt;- simdata3[p1==TRUE &amp; t==1,mean(iMr),by=q]
pD &lt;- data.table(q=2:min(length(pw0[,q]),length(pw1 [,q])+1))
for (iter in 1:10){
  pD[q==iter, lw := pw1[q==iter,2] - pw0[q==iter,2]]
  pD[q==iter, lc := pc1[q==iter,2] - pc0[q==iter,2]]
  pD[q==iter, lh := ph1[q==iter,2] - ph0[q==iter,2]]
  pD[q==iter, iMr := iMr1[q==iter,2] - iMr0[q==iter,2]]
}
pander(summary(pD[,lm(lw ~ lc + lh + iMr)]))</code></pre>
<table style="width:86%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>lc</strong></td>
<td align="center">1.535</td>
<td align="center">0.02685</td>
<td align="center">57.15</td>
<td align="center">3.102e-08</td>
</tr>
<tr class="even">
<td align="center"><strong>lh</strong></td>
<td align="center">0.7937</td>
<td align="center">0.0914</td>
<td align="center">8.684</td>
<td align="center">0.0003349</td>
</tr>
<tr class="odd">
<td align="center"><strong>iMr</strong></td>
<td align="center">0.02118</td>
<td align="center">0.02783</td>
<td align="center">0.7613</td>
<td align="center">0.4808</td>
</tr>
<tr class="even">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">0.2192</td>
<td align="center">0.004432</td>
<td align="center">49.46</td>
<td align="center">6.387e-08</td>
</tr>
</tbody>
</table>
<table style="width:85%;">
<caption>Fitting linear model: lw ~ lc + lh + iMr</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="11%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">9</td>
<td align="center">0.007999</td>
<td align="center">0.9997</td>
<td align="center">0.9996</td>
</tr>
</tbody>
</table>
</div>

<!--<a href="https://github.com/you"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a> -->
<a class="github-fork-ribbon right-bottom fixed" href="https://github.com/floswald/ScPo-Labor" title="Fork me on GitHub">Fork me on GitHub</a>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
